{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxOHnJOHo8bl"
      },
      "source": [
        "Wandb에 로그인하여 개인 api key를 넣어주세요 -> 체크포인트는 자동으로 매 에폭마다 완디비로 올라갑니다. -> 학습 중간에 끊기면 완디비에서 artifact를 다운받아 이어서 하면 됩니다. -> 동영상 평가는 영상을 업로드하고 input에 경로를 지정하면 output 동영상이 만들어집니다. -> output 영상을 다운받으면 됩니다.\n",
        "\n",
        "** 가끔 AttributeError: Can't get attribute 'DFLoss' on.. 오류 뜨는데 ultralytics 버전이 달라서 그런겁니다.\n",
        "\n",
        "1. import\n",
        "1. 데이터\n",
        "1. 모델 학습\n",
        "1. 모델 중단시 학습 재개\\\n",
        "1. 모델 평가\n",
        "1. 모델 영상 평가"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kyEHE9hWXa4",
        "outputId": "7b4a975b-7c0e-41e2-f14a-eb7d6b156795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 이미지 디렉토리와 라벨 디렉토리 경로 설정\n",
        "image_dir = '/content/drive/MyDrive/배경'\n",
        "label_dir = '/content/drive/MyDrive/배경 라벨 폴더'\n",
        "\n",
        "# 이미지 파일 목록 가져오기\n",
        "image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "for image_file in image_files:\n",
        "    # 라벨 파일 경로 설정\n",
        "    label_file = os.path.splitext(image_file)[0] + '.txt'\n",
        "    label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "    # 빈 라벨 파일 생성\n",
        "    with open(label_path, 'w') as f:\n",
        "        pass\n",
        "\n",
        "print(\"빈 라벨 파일 생성 완료.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F42gtZO5WrhC",
        "outputId": "8f068e9f-a440-4c2e-faec-cb4c180af739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "빈 라벨 파일 생성 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "O_D486Vy33nA"
      },
      "outputs": [],
      "source": [
        "# 1. import\n",
        "\n",
        "!pip install ultralytics\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "# !pip install --upgrade ultralytics==8.0.186 wandb\n",
        "!pip install wandb\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install opencv-python numpy matplotlib Pillow\n",
        "\n",
        "import os\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import shutil\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.optim as optim\n",
        "from ultralytics import YOLO\n",
        "from google.colab import drive\n",
        "import wandb\n",
        "wandb.login()\n",
        "# drive.mount('/content/drive')\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKsvLEb0Zjff"
      },
      "outputs": [],
      "source": [
        "# 2. 데이터\n",
        "\n",
        "!curl  -L \"https://app.roboflow.com/ds/28liIAkWiN?key=6Qrz2eATSn\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip    #640 이미지\n",
        "\n",
        "!mv /content/train /content/dataset\n",
        "\n",
        "images_list = os.listdir('/content/dataset/images')\n",
        "labels_list = os.listdir('/content/dataset/labels')\n",
        "os.mkdir('/content/dataset/images/train')\n",
        "os.mkdir('/content/dataset/labels/train')\n",
        "os.mkdir('/content/dataset/images/val')\n",
        "os.mkdir('/content/dataset/labels/val')\n",
        "os.mkdir('/content/dataset/images/test')\n",
        "os.mkdir('/content/dataset/labels/test')\n",
        "X_train, X_test, y_train, y_test = train_test_split(images_list, labels_list, test_size=0.1, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "for file in X_train:\n",
        "    shutil.move(os.path.join('/content/dataset/images', file), os.path.join('/content/dataset/images/train', file))\n",
        "    shutil.move(os.path.join('/content/dataset/labels', file.replace('.jpg', '.txt')), os.path.join('/content/dataset/labels/train', file.replace('.jpg', '.txt')))\n",
        "\n",
        "for file in X_test:\n",
        "    shutil.move(os.path.join('/content/dataset/images', file), os.path.join('/content/dataset/images/test', file))\n",
        "    shutil.move(os.path.join('/content/dataset/labels', file.replace('.jpg', '.txt')), os.path.join('/content/dataset/labels/test', file.replace('.jpg', '.txt')))\n",
        "\n",
        "for file in X_val:\n",
        "    shutil.move(os.path.join('/content/dataset/images', file), os.path.join('/content/dataset/images/val', file))\n",
        "    shutil.move(os.path.join('/content/dataset/labels', file.replace('.jpg', '.txt')), os.path.join('/content/dataset/labels/val', file.replace('.jpg', '.txt')))\n",
        "\n",
        "del images_list,labels_list,X_train, X_test, y_train, y_test, X_val, y_val\n",
        "\n",
        "with open('/content/dataset/data.yaml', 'w') as f:\n",
        "    f.write('train: /content/dataset/images/train\\n')\n",
        "    f.write('val: /content/dataset/images/val\\n')\n",
        "    f.write('test: /content/dataset/images/test\\n')\n",
        "    f.write('nc: 4\\n')\n",
        "    f.write('names: [\\'Bird\\', \\'Drone\\', \\'F.W.Drone\\', \\'Hellicopter\\']\\n')\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcneBL6m8znx"
      },
      "outputs": [],
      "source": [
        "# 3.모델 학습시키기\n",
        "\n",
        "from wandb.integration.ultralytics import add_wandb_callback\n",
        "\n",
        "wandb.init(project=\"YOLOv8m바꾼 파라미터\", job_type=\"training\")\n",
        "\n",
        "model = YOLO(\"yolov8m.pt\")\n",
        "\n",
        "add_wandb_callback(model, enable_model_checkpointing=True)\n",
        "\n",
        "model.train(\n",
        "    project=\"yolov8m\",\n",
        "    data=\"/content/dataset/data.yaml\",\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    patience=15,\n",
        "    batch=64,\n",
        "    augment=False,\n",
        "    cls = 3.0,\n",
        "    lr0=0.001)\n",
        "\n",
        "# model.val()\n",
        "\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1Qr2lDRmaSc"
      },
      "outputs": [],
      "source": [
        "# 4. 모델 학습 재개\n",
        "\n",
        "import wandb\n",
        "run = wandb.init()\n",
        "artifact = run.use_artifact('suhyoun0106-hahahaha/YOLOv8nYHHHH/run_wnbt3643_model:v100', type='model')\n",
        "artifact_dir = artifact.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l_LHvqvmdQj"
      },
      "outputs": [],
      "source": [
        "from wandb.integration.ultralytics import add_wandb_callback\n",
        "\n",
        "model = YOLO(\"\")\n",
        "\n",
        "add_wandb_callback(model, enable_model_checkpointing=True)\n",
        "\n",
        "model.train(\n",
        "    project=\"yolov8m\",\n",
        "    data=\"/content/dataset/data.yaml\",\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    patience=15,\n",
        "    batch=64,\n",
        "    augment=False,\n",
        "    cls = 3.0\n",
        "    lr0=0.001)\n",
        "\n",
        "# model.val()\n",
        "\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISw_CHf7qjBX"
      },
      "outputs": [],
      "source": [
        "# 5. 모델 평가\n",
        "import wandb\n",
        "run = wandb.init()\n",
        "artifact = run.use_artifact('suhyoun0106-hahahaha/YOLOv8M 그레이 스케일링/run_h04celon_model:v54', type='model')\n",
        "artifact_dir = artifact.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWOZC8v2QD3A"
      },
      "outputs": [],
      "source": [
        "model = YOLO('/content/artifacts/run_h04celon_model:v54/epoch54.pt')  # best.pt 파일 경로를 지정하세요\n",
        "\n",
        "metrics = model.val(data='/content/dataset/data.yaml')     # 데이터셋 설정 파일 경로\n",
        "\n",
        "print(f\"mAP@0.5: {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGlNWLxseljF"
      },
      "outputs": [],
      "source": [
        "# 6. 모델 영상 평가\n",
        "\n",
        "!pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "model = YOLO(\"/content/artifacts/run_h04celon_model:v54/epoch54.pt\")\n",
        "\n",
        "\n",
        "input_video_path = \"/content/종합 test 영상.mp4\"  # 비디오 파일 경로\n",
        "output_video_path = \"/content/output_video~~~.mp4\"\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "\n",
        "    results = model.predict(frame, imgsz=640, conf=0.2, iou=0.9, agnostic_nms=True, augment=True)\n",
        "\n",
        "\n",
        "    res_plotted = results[0].plot()\n",
        "\n",
        "\n",
        "    out.write(res_plotted)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}